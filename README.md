# ğŸ¤– Social Bot Detection using Transformer Models

This project implements a **Social Bot Detection System** using **fine-tuned Transformer-based Language Models** to classify social media posts as **Human** or **Bot**.

---

## ğŸ“Œ Project Motivation

Social bots play a major role in spreading misinformation and automated propaganda.  
This project aims to detect bot-generated content using **state-of-the-art NLP models**.

---

## ğŸ§  Models Used

- BERT (bert-base-uncased)
- RoBERTa (roberta-base)
- DistilBERT (distilbert-base-uncased)
- XLM-RoBERTa (xlm-roberta-base)

Architecture:
- CLS token embedding
- Feedforward Neural Network
- Sigmoid activation

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ compare_predict.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ evaluate_models.py
â”œâ”€â”€ plot_confusion_matrix.py
â”œâ”€â”€ train_tweetfake_dataset.py
â”œâ”€â”€ train_fox8_dataset.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Paper/
â”œâ”€â”€ Final paper/
â””â”€â”€ README.md
```

---

## ğŸ“Š Datasets

### TweetFake Dataset
- Balanced human/bot dataset

### Fox Dataset
- Format: user_id, label, text
- Used for domain generalization

---

## âš™ï¸ Installation

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸš€ Training

### Train on TweetFake
```bash
python train_tweetfake_dataset.py
```

### Train on Fox Dataset (1 epoch)
```bash
python train_fox8_dataset.py
```

---

## ğŸ” Prediction

Single model:
```bash
python predict.py
```

All models:
```bash
python compare_predict.py
```

---

## ğŸ“ˆ Evaluation

```bash
python evaluate_models.py
```

Metrics:
- Accuracy
- Precision
- Recall
- F1-score

---

## ğŸ“Š Confusion Matrix

```bash
python plot_confusion_matrix.py
```

---

## ğŸ–¥ï¸ Streamlit Apps

Prediction UI:
```bash
streamlit run app.py
```

Metrics Dashboard:
```bash
streamlit run app_metrics.py
```

---

## ğŸ§ª Training Strategy

- Training performed on Google Colab (GPU)
- Local machine used for inference and demo

---

## ğŸ“ Academic Notes

- Transformers capture contextual semantics
- F1-score balances precision and recall
- Multiple models enable comparative analysis

---

## ğŸ“„ Research Paper

IEEE paper available in `Paper/`  
Final report in `Final paper/`

---

## ğŸ“œ License

Academic and research use only.
